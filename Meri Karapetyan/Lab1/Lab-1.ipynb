{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "authorship_tag": "ABX9TyPwxmrnq8spXGNFJyelV7YX"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3 (ipykernel)",
   "language": "python"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "St1eYKuxtm7j",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1758222878012,
     "user_tz": -240,
     "elapsed": 17,
     "user": {
      "displayName": "Srbuhi Pupuyan",
      "userId": "12066682202247757736"
     }
    },
    "outputId": "4d4b2fc4-8805-42e3-8a5d-013d6c2bd27d",
    "ExecuteTime": {
     "end_time": "2025-10-02T09:21:43.274184Z",
     "start_time": "2025-10-02T09:21:43.248481Z"
    }
   },
   "source": [
    "import string\n",
    "\n",
    "text = \"\"\"Natural Language Processing (NLP) is a subfield of linguistics, computer science, and artificial\n",
    "intelligence concerned with the interactions between computers and human language. It's used to\n",
    "analyze text, allowing machines to understand, interpret, and manipulate human language. NLP has\n",
    "many real-world applications, including machine translation, sentiment analysis, and chatbots.\"\"\"\n",
    "\n",
    "tokens = text.split()\n",
    "print(f\"Tokens:\\n{tokens}\\n\")\n",
    "\n",
    "# Lowercasing\n",
    "lower_tokens = [t.lower() for t in tokens]\n",
    "print(f\"Lowercased:\\n{lower_tokens}\\n\")\n",
    "\n",
    "# Punctuation Removal\n",
    "def remove_punctuation(token_list):\n",
    "    return [\n",
    "        ''.join(char for char in word if char not in string.punctuation)\n",
    "        for word in token_list\n",
    "        if ''.join(char for char in word if char not in string.punctuation) != \"\"\n",
    "    ]\n",
    "\n",
    "tokens_clean = remove_punctuation(lower_tokens)\n",
    "print(f\"Tokens without punctuation:\\n{tokens_clean}\\n\")\n",
    "\n",
    "# Stopword Removal\n",
    "stop_words = {\"the\", \"is\", \"and\", \"a\", \"an\", \"in\", \"on\", \"at\", \"for\", \"to\", \"of\", \"are\"}\n",
    "\n",
    "tokens_no_stopwords = [word for word in tokens_clean if word not in stop_words]\n",
    "print(f\"Tokens without stopwords:\\n{tokens_no_stopwords}\\n\")\n",
    "\n",
    "#  Stemming\n",
    "def simple_stem(word):\n",
    "    suffixes = [\n",
    "        \"ing\", \"ed\", \"ics\", \"ial\", \"ence\", \"ious\", \"ous\", \"age\",\n",
    "        \"al\", \"wise\", \"ity\", \"ty\", \"ment\", \"ness\", \"ship\", \"ion\", \"s\"\n",
    "    ]\n",
    "    for suffix in suffixes:\n",
    "        if word.endswith(suffix) and len(word) > len(suffix) + 2:\n",
    "            return word[:-len(suffix)]\n",
    "    return word\n",
    "\n",
    "stemmed_tokens = [simple_stem(word) for word in tokens_no_stopwords]\n",
    "print(f\"Stemmed tokens:\\n{stemmed_tokens}\\n\")\n",
    "\n",
    "# Lemmatization\n",
    "lemma_map = {\n",
    "    \"is\": \"be\", \"are\": \"be\", \"was\": \"be\", \"were\": \"be\",\n",
    "    \"has\": \"have\", \"had\": \"have\", \"does\": \"do\", \"did\": \"do\",\n",
    "    \"machines\": \"machine\", \"computers\": \"computer\",\n",
    "    \"applications\": \"application\", \"interactions\": \"interaction\",\n",
    "    \"languages\": \"language\"\n",
    "}\n",
    "\n",
    "def lemmatize(word):\n",
    "    return lemma_map.get(word, word)\n",
    "\n",
    "lemmatized_tokens = [lemmatize(word) for word in tokens_no_stopwords]\n",
    "print(f\"Lemmatized tokens:\\n{lemmatized_tokens}\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens:\n",
      "['Natural', 'Language', 'Processing', '(NLP)', 'is', 'a', 'subfield', 'of', 'linguistics,', 'computer', 'science,', 'and', 'artificial', 'intelligence', 'concerned', 'with', 'the', 'interactions', 'between', 'computers', 'and', 'human', 'language.', \"It's\", 'used', 'to', 'analyze', 'text,', 'allowing', 'machines', 'to', 'understand,', 'interpret,', 'and', 'manipulate', 'human', 'language.', 'NLP', 'has', 'many', 'real-world', 'applications,', 'including', 'machine', 'translation,', 'sentiment', 'analysis,', 'and', 'chatbots.']\n",
      "\n",
      "Lowercased:\n",
      "['natural', 'language', 'processing', '(nlp)', 'is', 'a', 'subfield', 'of', 'linguistics,', 'computer', 'science,', 'and', 'artificial', 'intelligence', 'concerned', 'with', 'the', 'interactions', 'between', 'computers', 'and', 'human', 'language.', \"it's\", 'used', 'to', 'analyze', 'text,', 'allowing', 'machines', 'to', 'understand,', 'interpret,', 'and', 'manipulate', 'human', 'language.', 'nlp', 'has', 'many', 'real-world', 'applications,', 'including', 'machine', 'translation,', 'sentiment', 'analysis,', 'and', 'chatbots.']\n",
      "\n",
      "Tokens without punctuation:\n",
      "['natural', 'language', 'processing', 'nlp', 'is', 'a', 'subfield', 'of', 'linguistics', 'computer', 'science', 'and', 'artificial', 'intelligence', 'concerned', 'with', 'the', 'interactions', 'between', 'computers', 'and', 'human', 'language', 'its', 'used', 'to', 'analyze', 'text', 'allowing', 'machines', 'to', 'understand', 'interpret', 'and', 'manipulate', 'human', 'language', 'nlp', 'has', 'many', 'realworld', 'applications', 'including', 'machine', 'translation', 'sentiment', 'analysis', 'and', 'chatbots']\n",
      "\n",
      "Tokens without stopwords:\n",
      "['natural', 'language', 'processing', 'nlp', 'subfield', 'linguistics', 'computer', 'science', 'artificial', 'intelligence', 'concerned', 'with', 'interactions', 'between', 'computers', 'human', 'language', 'its', 'used', 'analyze', 'text', 'allowing', 'machines', 'understand', 'interpret', 'manipulate', 'human', 'language', 'nlp', 'has', 'many', 'realworld', 'applications', 'including', 'machine', 'translation', 'sentiment', 'analysis', 'chatbots']\n",
      "\n",
      "Stemmed tokens:\n",
      "['natur', 'langu', 'process', 'nlp', 'subfield', 'linguist', 'computer', 'sci', 'artific', 'intellig', 'concern', 'with', 'interaction', 'between', 'computer', 'human', 'langu', 'its', 'used', 'analyze', 'text', 'allow', 'machine', 'understand', 'interpret', 'manipulate', 'human', 'langu', 'nlp', 'has', 'many', 'realworld', 'application', 'includ', 'machine', 'translat', 'senti', 'analysi', 'chatbot']\n",
      "\n",
      "Lemmatized tokens:\n",
      "['natural', 'language', 'processing', 'nlp', 'subfield', 'linguistics', 'computer', 'science', 'artificial', 'intelligence', 'concerned', 'with', 'interaction', 'between', 'computer', 'human', 'language', 'its', 'used', 'analyze', 'text', 'allowing', 'machine', 'understand', 'interpret', 'manipulate', 'human', 'language', 'nlp', 'have', 'many', 'realworld', 'application', 'including', 'machine', 'translation', 'sentiment', 'analysis', 'chatbots']\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": ""
  }
 ]
}
