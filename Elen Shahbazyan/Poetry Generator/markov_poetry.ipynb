{
 "cells": [
  {
   "cell_type": "code",
   "id": "89443187",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-16T20:30:16.559750Z",
     "start_time": "2025-10-16T20:30:16.545722Z"
    }
   },
   "source": [
    "import re\n",
    "import random\n",
    "from collections import Counter, defaultdict\n",
    "import sys\n",
    "\n",
    "INPUT_FILE = \"robert_frost.txt\"\n",
    "END_TOKEN = \"END\"\n",
    "LINES_TO_GENERATE = 4\n",
    "MAX_WORDS_PER_LINE = 50\n"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "463d0339",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-16T20:30:16.599992Z",
     "start_time": "2025-10-16T20:30:16.594907Z"
    }
   },
   "source": [
    "def clean_line(line: str) -> str:\n",
    "    cleaned = re.sub(r\"[^\\w\\s]\", \"\", line)\n",
    "    return cleaned.lower().strip()\n"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "800647f0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-16T20:30:16.973966Z",
     "start_time": "2025-10-16T20:30:16.961272Z"
    }
   },
   "source": [
    "def cumulative_choice(prob_dict):\n",
    "    if not prob_dict:\n",
    "        raise ValueError(\"Empty probability distribution in cumulative_choice.\")\n",
    "    items = list(prob_dict.items())\n",
    "    total = sum(p for _, p in items)\n",
    "    if total <= 0:\n",
    "        raise ValueError(\"Non-positive total probability in cumulative_choice.\")\n",
    "    r = random.random()\n",
    "    cumulative = 0.0\n",
    "    for word, p in items:\n",
    "        cumulative += (p / total)\n",
    "        if r <= cumulative:\n",
    "            return word\n",
    "    return items[-1][0]\n"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "id": "bf436328",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-16T20:30:17.034249Z",
     "start_time": "2025-10-16T20:30:17.017913Z"
    }
   },
   "source": [
    "def train_from_file(filename: str):\n",
    "    try:\n",
    "        with open(filename, \"r\", encoding=\"utf-8\") as f:\n",
    "            raw_lines = f.readlines()\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: file '{filename}' not found. Put 'robert_frost.txt' in the same folder.\", file=sys.stderr)\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading '{filename}': {e}\", file=sys.stderr)\n",
    "        return None\n",
    "\n",
    "    initial_counts = Counter()\n",
    "    unigram_counts = Counter()\n",
    "    first_counts = defaultdict(Counter)\n",
    "    second_counts = defaultdict(Counter)\n",
    "    total_nonempty_lines = 0\n",
    "\n",
    "    for raw in raw_lines:\n",
    "        line = raw.strip()\n",
    "        if not line:\n",
    "            continue\n",
    "        cleaned = clean_line(line)\n",
    "        if not cleaned:\n",
    "            continue\n",
    "        words = cleaned.split()\n",
    "        if not words:\n",
    "            continue\n",
    "\n",
    "        total_nonempty_lines += 1\n",
    "        initial_counts[words[0]] += 1\n",
    "\n",
    "        for i, w in enumerate(words):\n",
    "            unigram_counts[w] += 1\n",
    "            if i >= 1:\n",
    "                prev = words[i-1]\n",
    "                first_counts[prev][w] += 1\n",
    "            if i >= 2:\n",
    "                prevbig = (words[i-2], words[i-1])\n",
    "                second_counts[prevbig][w] += 1\n",
    "\n",
    "        last = words[-1]\n",
    "        first_counts[last][END_TOKEN] += 1\n",
    "        unigram_counts[END_TOKEN] += 1\n",
    "        if len(words) >= 2:\n",
    "            prevbig = (words[-2], words[-1])\n",
    "            second_counts[prevbig][END_TOKEN] += 1\n",
    "\n",
    "    if total_nonempty_lines == 0:\n",
    "        print(\"Error: no non-empty lines found in the input file.\", file=sys.stderr)\n",
    "        return None\n",
    "\n",
    "    initial_probs = {w: c / total_nonempty_lines for w, c in initial_counts.items()}\n",
    "\n",
    "    first_probs = {}\n",
    "    for prev, counter in first_counts.items():\n",
    "        total_for_prev = sum(counter.values())\n",
    "        if total_for_prev > 0:\n",
    "            first_probs[prev] = {nxt: cnt / total_for_prev for nxt, cnt in counter.items()}\n",
    "\n",
    "    second_probs = {}\n",
    "    for prevbig, counter in second_counts.items():\n",
    "        total_for_prevbig = sum(counter.values())\n",
    "        if total_for_prevbig > 0:\n",
    "            second_probs[prevbig] = {nxt: cnt / total_for_prevbig for nxt, cnt in counter.items()}\n",
    "\n",
    "    total_unigrams = sum(unigram_counts.values())\n",
    "    unigram_probs = {w: c / total_unigrams for w, c in unigram_counts.items()}\n",
    "\n",
    "    return {\n",
    "        \"initial_probs\": initial_probs,\n",
    "        \"first_probs\": first_probs,\n",
    "        \"second_probs\": second_probs,\n",
    "        \"unigram_probs\": unigram_probs,\n",
    "        \"counts\": {\n",
    "            \"initial_counts\": initial_counts,\n",
    "            \"first_counts\": first_counts,\n",
    "            \"second_counts\": second_counts,\n",
    "            \"unigram_counts\": unigram_counts,\n",
    "            \"total_lines\": total_nonempty_lines\n",
    "        }\n",
    "    }\n"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "id": "8837de11",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-16T20:30:17.181843Z",
     "start_time": "2025-10-16T20:30:17.171880Z"
    }
   },
   "source": [
    "def generate_line(model):\n",
    "    initial = model[\"initial_probs\"]\n",
    "    first_probs = model[\"first_probs\"]\n",
    "    second_probs = model[\"second_probs\"]\n",
    "    unigram_probs = model[\"unigram_probs\"]\n",
    "\n",
    "    w1 = cumulative_choice(initial)\n",
    "    if w1 == END_TOKEN:\n",
    "        return \"\"\n",
    "    words = [w1]\n",
    "\n",
    "    if w1 in first_probs:\n",
    "        w2 = cumulative_choice(first_probs[w1])\n",
    "    else:\n",
    "        w2 = cumulative_choice(unigram_probs)\n",
    "    if w2 == END_TOKEN:\n",
    "        return \" \".join(words)\n",
    "\n",
    "    words.append(w2)\n",
    "\n",
    "    for _ in range(MAX_WORDS_PER_LINE - 2):\n",
    "        context = (words[-2], words[-1])\n",
    "        next_word = None\n",
    "        if context in second_probs:\n",
    "            next_word = cumulative_choice(second_probs[context])\n",
    "        elif words[-1] in first_probs:\n",
    "            next_word = cumulative_choice(first_probs[words[-1]])\n",
    "        else:\n",
    "            next_word = cumulative_choice(unigram_probs)\n",
    "\n",
    "        if next_word == END_TOKEN:\n",
    "            break\n",
    "        words.append(next_word)\n",
    "\n",
    "    return \" \".join(words)\n"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "id": "3e8e9bf0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-16T20:30:17.268961Z",
     "start_time": "2025-10-16T20:30:17.262266Z"
    }
   },
   "source": [
    "def generate_poem(model, n_lines=LINES_TO_GENERATE):\n",
    "    return [generate_line(model) for _ in range(n_lines)]\n"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "id": "a1e7a5ec",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-16T20:30:18.313591Z",
     "start_time": "2025-10-16T20:30:18.227875Z"
    }
   },
   "source": [
    "model = train_from_file(INPUT_FILE)\n",
    "if model is None:\n",
    "    print(\"Model training failed. Make sure 'robert_frost.txt' is available.\")\n",
    "else:\n",
    "    print(f\"Trained on {model['counts']['total_lines']} non-empty lines.\\n\")\n",
    "    print(\"Sample initial word probabilities (top 10):\")\n",
    "    sorted_initial = sorted(model[\"initial_probs\"].items(), key=lambda x: -x[1])\n",
    "    for w, p in sorted_initial[:10]:\n",
    "        print(f\"  {w!r}: {p:.3f}\")\n",
    "    print(\"\\nGenerated poem:\\n\")\n",
    "    poem = generate_poem(model, LINES_TO_GENERATE)\n",
    "    for line in poem:\n",
    "        print(line)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained on 1436 non-empty lines.\n",
      "\n",
      "Sample initial word probabilities (top 10):\n",
      "  'and': 0.090\n",
      "  'i': 0.082\n",
      "  'the': 0.057\n",
      "  'but': 0.036\n",
      "  'to': 0.035\n",
      "  'you': 0.028\n",
      "  'he': 0.024\n",
      "  'a': 0.021\n",
      "  'in': 0.020\n",
      "  'of': 0.020\n",
      "\n",
      "Generated poem:\n",
      "\n",
      "or vase or picture\n",
      "i have no doubt its grown up some to woods around it\n",
      "over\n",
      "once told me\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "c02d019bfe56ee9b"
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
