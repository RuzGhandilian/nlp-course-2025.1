{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-25T20:00:37.283977Z",
     "start_time": "2025-09-25T20:00:37.278507Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import string\n",
    "sample_text = \" Natural Language Processing (NLP) is a subfield of linguistics, computer science, and artificial intelligence concerned with the interactions between computers and human language. It's used to analyze text, allowing machines to understand, interpret, and manipulate human language. NLP has many real-world applications, including machine translation, sentiment analysis, and chatbots. babies, companies \""
   ],
   "id": "627a84371ba44b4",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-25T20:00:37.315462Z",
     "start_time": "2025-09-25T20:00:37.310075Z"
    }
   },
   "cell_type": "code",
   "source": "print('Original Text:', sample_text)",
   "id": "dd9d5a921d81a919",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Text:  Natural Language Processing (NLP) is a subfield of linguistics, computer science, and artificial intelligence concerned with the interactions between computers and human language. It's used to analyze text, allowing machines to understand, interpret, and manipulate human language. NLP has many real-world applications, including machine translation, sentiment analysis, and chatbots. babies, companies \n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#1split",
   "id": "a6b21ba27ca18bf8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-25T20:00:37.398271Z",
     "start_time": "2025-09-25T20:00:37.390412Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tokens = sample_text.split()\n",
    "tokens"
   ],
   "id": "e0268e42b61bd5b4",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Natural',\n",
       " 'Language',\n",
       " 'Processing',\n",
       " '(NLP)',\n",
       " 'is',\n",
       " 'a',\n",
       " 'subfield',\n",
       " 'of',\n",
       " 'linguistics,',\n",
       " 'computer',\n",
       " 'science,',\n",
       " 'and',\n",
       " 'artificial',\n",
       " 'intelligence',\n",
       " 'concerned',\n",
       " 'with',\n",
       " 'the',\n",
       " 'interactions',\n",
       " 'between',\n",
       " 'computers',\n",
       " 'and',\n",
       " 'human',\n",
       " 'language.',\n",
       " \"It's\",\n",
       " 'used',\n",
       " 'to',\n",
       " 'analyze',\n",
       " 'text,',\n",
       " 'allowing',\n",
       " 'machines',\n",
       " 'to',\n",
       " 'understand,',\n",
       " 'interpret,',\n",
       " 'and',\n",
       " 'manipulate',\n",
       " 'human',\n",
       " 'language.',\n",
       " 'NLP',\n",
       " 'has',\n",
       " 'many',\n",
       " 'real-world',\n",
       " 'applications,',\n",
       " 'including',\n",
       " 'machine',\n",
       " 'translation,',\n",
       " 'sentiment',\n",
       " 'analysis,',\n",
       " 'and',\n",
       " 'chatbots.',\n",
       " 'babies,',\n",
       " 'companies']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#2Lowercasing",
   "id": "b67eee62f0bb6eb6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-25T20:00:37.448035Z",
     "start_time": "2025-09-25T20:00:37.441556Z"
    }
   },
   "cell_type": "code",
   "source": [
    "lowercase_tokens = [i.lower() for i in tokens]\n",
    "lowercase_tokens"
   ],
   "id": "694897885a7e4ac9",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['natural',\n",
       " 'language',\n",
       " 'processing',\n",
       " '(nlp)',\n",
       " 'is',\n",
       " 'a',\n",
       " 'subfield',\n",
       " 'of',\n",
       " 'linguistics,',\n",
       " 'computer',\n",
       " 'science,',\n",
       " 'and',\n",
       " 'artificial',\n",
       " 'intelligence',\n",
       " 'concerned',\n",
       " 'with',\n",
       " 'the',\n",
       " 'interactions',\n",
       " 'between',\n",
       " 'computers',\n",
       " 'and',\n",
       " 'human',\n",
       " 'language.',\n",
       " \"it's\",\n",
       " 'used',\n",
       " 'to',\n",
       " 'analyze',\n",
       " 'text,',\n",
       " 'allowing',\n",
       " 'machines',\n",
       " 'to',\n",
       " 'understand,',\n",
       " 'interpret,',\n",
       " 'and',\n",
       " 'manipulate',\n",
       " 'human',\n",
       " 'language.',\n",
       " 'nlp',\n",
       " 'has',\n",
       " 'many',\n",
       " 'real-world',\n",
       " 'applications,',\n",
       " 'including',\n",
       " 'machine',\n",
       " 'translation,',\n",
       " 'sentiment',\n",
       " 'analysis,',\n",
       " 'and',\n",
       " 'chatbots.',\n",
       " 'babies,',\n",
       " 'companies']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#3Punctuation",
   "id": "d754a77a55500154"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-25T20:00:37.494005Z",
     "start_time": "2025-09-25T20:00:37.489590Z"
    }
   },
   "cell_type": "code",
   "source": "print(string.punctuation)",
   "id": "12aadf0363492ba6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-25T20:00:37.518419Z",
     "start_time": "2025-09-25T20:00:37.512048Z"
    }
   },
   "cell_type": "code",
   "source": [
    "cleaned_tokens = []\n",
    "\n",
    "for token in lowercase_tokens:\n",
    "    clean_token = ''.join([char for char in token if char not in string.punctuation])\n",
    "    cleaned_tokens.append(clean_token)\n",
    "\n",
    "cleaned_tokens"
   ],
   "id": "a3d53f3440f72c7a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['natural',\n",
       " 'language',\n",
       " 'processing',\n",
       " 'nlp',\n",
       " 'is',\n",
       " 'a',\n",
       " 'subfield',\n",
       " 'of',\n",
       " 'linguistics',\n",
       " 'computer',\n",
       " 'science',\n",
       " 'and',\n",
       " 'artificial',\n",
       " 'intelligence',\n",
       " 'concerned',\n",
       " 'with',\n",
       " 'the',\n",
       " 'interactions',\n",
       " 'between',\n",
       " 'computers',\n",
       " 'and',\n",
       " 'human',\n",
       " 'language',\n",
       " 'its',\n",
       " 'used',\n",
       " 'to',\n",
       " 'analyze',\n",
       " 'text',\n",
       " 'allowing',\n",
       " 'machines',\n",
       " 'to',\n",
       " 'understand',\n",
       " 'interpret',\n",
       " 'and',\n",
       " 'manipulate',\n",
       " 'human',\n",
       " 'language',\n",
       " 'nlp',\n",
       " 'has',\n",
       " 'many',\n",
       " 'realworld',\n",
       " 'applications',\n",
       " 'including',\n",
       " 'machine',\n",
       " 'translation',\n",
       " 'sentiment',\n",
       " 'analysis',\n",
       " 'and',\n",
       " 'chatbots',\n",
       " 'babies',\n",
       " 'companies']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#4Stop Word Removal",
   "id": "2eae6c578a8c0df1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-25T20:00:37.536409Z",
     "start_time": "2025-09-25T20:00:37.531942Z"
    }
   },
   "cell_type": "code",
   "source": [
    "stop_words = [\"the\", \"a\", \"an\", \"in\", \"on\", \"at\", \"for\", \"to\", \"of\",\n",
    "            \"and\", \"is\", \"are\", 'but', 'if', 'so']"
   ],
   "id": "1a99cd38acf40eb5",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-25T20:00:37.557605Z",
     "start_time": "2025-09-25T20:00:37.551691Z"
    }
   },
   "cell_type": "code",
   "source": [
    "filtered_tokens = [i for i in cleaned_tokens if i not in stop_words]\n",
    "filtered_tokens"
   ],
   "id": "bf63961edcda4718",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['natural',\n",
       " 'language',\n",
       " 'processing',\n",
       " 'nlp',\n",
       " 'subfield',\n",
       " 'linguistics',\n",
       " 'computer',\n",
       " 'science',\n",
       " 'artificial',\n",
       " 'intelligence',\n",
       " 'concerned',\n",
       " 'with',\n",
       " 'interactions',\n",
       " 'between',\n",
       " 'computers',\n",
       " 'human',\n",
       " 'language',\n",
       " 'its',\n",
       " 'used',\n",
       " 'analyze',\n",
       " 'text',\n",
       " 'allowing',\n",
       " 'machines',\n",
       " 'understand',\n",
       " 'interpret',\n",
       " 'manipulate',\n",
       " 'human',\n",
       " 'language',\n",
       " 'nlp',\n",
       " 'has',\n",
       " 'many',\n",
       " 'realworld',\n",
       " 'applications',\n",
       " 'including',\n",
       " 'machine',\n",
       " 'translation',\n",
       " 'sentiment',\n",
       " 'analysis',\n",
       " 'chatbots',\n",
       " 'babies',\n",
       " 'companies']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#5Stemming",
   "id": "c085eab7bcb42af6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-25T20:00:37.579064Z",
     "start_time": "2025-09-25T20:00:37.572689Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Common suffix rules (ordered by priority)\n",
    "suffix_rules = [\n",
    "    ('ational', 'ate'), ('tional', 'tion'),\n",
    "    ('enci', 'ence'), ('anci', 'ance'),\n",
    "    ('izer', 'ize'), ('ator', 'ate'),\n",
    "    ('alli', 'al'), ('entli', 'ent'), ('eli', 'e'),\n",
    "    ('ousli', 'ous'),\n",
    "    ('ization', 'ize'), ('ation', 'ate'),\n",
    "    ('fulness', 'ful'), ('ousness', 'ous'), ('iveness', 'ive'),\n",
    "    ('ing', ''), ('ed', ''), ('er', ''), ('est', ''), ('ly', ''),\n",
    "    ('ment', ''), ('ness', ''), ('tion', ''), ('sion', ''),\n",
    "    ('able', ''), ('ible', ''), ('al', ''), ('ful', ''),\n",
    "    ('ous', ''), ('ive', ''), ('ic', ''),\n",
    "    ('ies', 'y'), ('s', ''),\n",
    "]"
   ],
   "id": "69d49b505e89dd8b",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-25T20:00:37.602287Z",
     "start_time": "2025-09-25T20:00:37.594960Z"
    }
   },
   "cell_type": "code",
   "source": [
    "stemmed_tokens = []\n",
    "for token in filtered_tokens:\n",
    "    if len(token) > 3:\n",
    "        stemmed = token\n",
    "        for suffix, replacement in suffix_rules:\n",
    "            if stemmed.endswith(suffix):\n",
    "                stemmed = stemmed[:-len(suffix)] + replacement\n",
    "                break\n",
    "\n",
    "        if len(stemmed) >= 2:\n",
    "            stemmed_tokens.append(stemmed)\n",
    "        else:\n",
    "            stemmed_tokens.append(token)\n",
    "    else:\n",
    "        stemmed_tokens.append(token)\n",
    "\n",
    "stemmed_tokens"
   ],
   "id": "73084b5cc54afbae",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['natur',\n",
       " 'language',\n",
       " 'process',\n",
       " 'nlp',\n",
       " 'subfield',\n",
       " 'linguistic',\n",
       " 'comput',\n",
       " 'science',\n",
       " 'artifici',\n",
       " 'intelligence',\n",
       " 'concern',\n",
       " 'with',\n",
       " 'interaction',\n",
       " 'between',\n",
       " 'computer',\n",
       " 'human',\n",
       " 'language',\n",
       " 'its',\n",
       " 'us',\n",
       " 'analyze',\n",
       " 'text',\n",
       " 'allow',\n",
       " 'machine',\n",
       " 'understand',\n",
       " 'interpret',\n",
       " 'manipulate',\n",
       " 'human',\n",
       " 'language',\n",
       " 'nlp',\n",
       " 'has',\n",
       " 'many',\n",
       " 'realworld',\n",
       " 'application',\n",
       " 'includ',\n",
       " 'machine',\n",
       " 'translate',\n",
       " 'senti',\n",
       " 'analysi',\n",
       " 'chatbot',\n",
       " 'baby',\n",
       " 'company']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#6lemmatization",
   "id": "91df98a3398132db"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-25T20:00:37.641153Z",
     "start_time": "2025-09-25T20:00:37.636909Z"
    }
   },
   "cell_type": "code",
   "source": [
    "lemma_dict = {\n",
    "    'am': 'be', 'is': 'be', 'are': 'be', 'was': 'be', 'were': 'be', 'been': 'be', 'being': 'be',\n",
    "    'better': 'good', 'best': 'good', 'worse': 'bad', 'worst': 'bad',\n",
    "\n",
    "    \"allowing\": 'allow',\n",
    "    'including': 'include',\n",
    "    \"processing\": 'process',\n",
    "    'used': 'use' ,\n",
    "    'concerned': 'concern',\n",
    "}"
   ],
   "id": "32985e7bf18c798c",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-25T20:00:37.656298Z",
     "start_time": "2025-09-25T20:00:37.650211Z"
    }
   },
   "cell_type": "code",
   "source": [
    "lemmatized_tokens = []\n",
    "for token in filtered_tokens:\n",
    "    if token in lemma_dict:\n",
    "        lemmatized_tokens.append(lemma_dict[token])\n",
    "    else:\n",
    "        lemmatized_tokens.append(token)\n",
    "\n",
    "lemmatized_tokens"
   ],
   "id": "a2cceb3a3c7aeaf8",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['natural',\n",
       " 'language',\n",
       " 'process',\n",
       " 'nlp',\n",
       " 'subfield',\n",
       " 'linguistics',\n",
       " 'computer',\n",
       " 'science',\n",
       " 'artificial',\n",
       " 'intelligence',\n",
       " 'concern',\n",
       " 'with',\n",
       " 'interactions',\n",
       " 'between',\n",
       " 'computers',\n",
       " 'human',\n",
       " 'language',\n",
       " 'its',\n",
       " 'use',\n",
       " 'analyze',\n",
       " 'text',\n",
       " 'allow',\n",
       " 'machines',\n",
       " 'understand',\n",
       " 'interpret',\n",
       " 'manipulate',\n",
       " 'human',\n",
       " 'language',\n",
       " 'nlp',\n",
       " 'has',\n",
       " 'many',\n",
       " 'realworld',\n",
       " 'applications',\n",
       " 'include',\n",
       " 'machine',\n",
       " 'translation',\n",
       " 'sentiment',\n",
       " 'analysis',\n",
       " 'chatbots',\n",
       " 'babies',\n",
       " 'companies']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 12
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
