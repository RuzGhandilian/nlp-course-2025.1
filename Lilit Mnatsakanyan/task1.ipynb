{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-09-13T17:06:12.465243Z",
     "start_time": "2025-09-13T17:06:12.454026Z"
    }
   },
   "source": [
    "text = \"\"\"Natural Language Processing (NLP) is a subfield of linguistics, computer science, and artificial\n",
    "intelligence concerned with the interactions between computers and human language. It's used to\n",
    "analyze text, allowing machines to understand, interpret, and manipulate human language. NLP has\n",
    "many real-world applications, including machine translation, sentiment analysis, and chatbots.\"\"\"\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-13T17:06:12.606750Z",
     "start_time": "2025-09-13T17:06:12.591677Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 1. Tokenization:\n",
    "tokens = text.split()\n",
    "tokens"
   ],
   "id": "6ec4691e6539782a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Natural',\n",
       " 'Language',\n",
       " 'Processing',\n",
       " '(NLP)',\n",
       " 'is',\n",
       " 'a',\n",
       " 'subfield',\n",
       " 'of',\n",
       " 'linguistics,',\n",
       " 'computer',\n",
       " 'science,',\n",
       " 'and',\n",
       " 'artificial',\n",
       " 'intelligence',\n",
       " 'concerned',\n",
       " 'with',\n",
       " 'the',\n",
       " 'interactions',\n",
       " 'between',\n",
       " 'computers',\n",
       " 'and',\n",
       " 'human',\n",
       " 'language.',\n",
       " \"It's\",\n",
       " 'used',\n",
       " 'to',\n",
       " 'analyze',\n",
       " 'text,',\n",
       " 'allowing',\n",
       " 'machines',\n",
       " 'to',\n",
       " 'understand,',\n",
       " 'interpret,',\n",
       " 'and',\n",
       " 'manipulate',\n",
       " 'human',\n",
       " 'language.',\n",
       " 'NLP',\n",
       " 'has',\n",
       " 'many',\n",
       " 'real-world',\n",
       " 'applications,',\n",
       " 'including',\n",
       " 'machine',\n",
       " 'translation,',\n",
       " 'sentiment',\n",
       " 'analysis,',\n",
       " 'and',\n",
       " 'chatbots.']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-13T17:06:12.638942Z",
     "start_time": "2025-09-13T17:06:12.624092Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import string\n",
    "\n",
    "# 2. Lowercasing:\n",
    "# 3. Punctuation Removal:\n",
    "tokens_clean = [word.lower().strip(string.punctuation) for word in tokens]\n",
    "tokens_clean"
   ],
   "id": "5b6aaa24ae4abf6a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['natural',\n",
       " 'language',\n",
       " 'processing',\n",
       " 'nlp',\n",
       " 'is',\n",
       " 'a',\n",
       " 'subfield',\n",
       " 'of',\n",
       " 'linguistics',\n",
       " 'computer',\n",
       " 'science',\n",
       " 'and',\n",
       " 'artificial',\n",
       " 'intelligence',\n",
       " 'concerned',\n",
       " 'with',\n",
       " 'the',\n",
       " 'interactions',\n",
       " 'between',\n",
       " 'computers',\n",
       " 'and',\n",
       " 'human',\n",
       " 'language',\n",
       " \"it's\",\n",
       " 'used',\n",
       " 'to',\n",
       " 'analyze',\n",
       " 'text',\n",
       " 'allowing',\n",
       " 'machines',\n",
       " 'to',\n",
       " 'understand',\n",
       " 'interpret',\n",
       " 'and',\n",
       " 'manipulate',\n",
       " 'human',\n",
       " 'language',\n",
       " 'nlp',\n",
       " 'has',\n",
       " 'many',\n",
       " 'real-world',\n",
       " 'applications',\n",
       " 'including',\n",
       " 'machine',\n",
       " 'translation',\n",
       " 'sentiment',\n",
       " 'analysis',\n",
       " 'and',\n",
       " 'chatbots']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-13T17:06:12.670034Z",
     "start_time": "2025-09-13T17:06:12.655651Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 4. Stop Word Removal:\n",
    "stop_words = [\"the\", \"a\", \"an\", \"in\", \"on\", \"at\", \"for\", \"to\", \"of\", \"and\", \"is\", \"are\"]\n",
    "\n",
    "tokens_stop_words_removed = [word for word in tokens_clean if word not in stop_words]\n",
    "tokens_stop_words_removed"
   ],
   "id": "59624fde2ce2df90",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['natural',\n",
       " 'language',\n",
       " 'processing',\n",
       " 'nlp',\n",
       " 'subfield',\n",
       " 'linguistics',\n",
       " 'computer',\n",
       " 'science',\n",
       " 'artificial',\n",
       " 'intelligence',\n",
       " 'concerned',\n",
       " 'with',\n",
       " 'interactions',\n",
       " 'between',\n",
       " 'computers',\n",
       " 'human',\n",
       " 'language',\n",
       " \"it's\",\n",
       " 'used',\n",
       " 'analyze',\n",
       " 'text',\n",
       " 'allowing',\n",
       " 'machines',\n",
       " 'understand',\n",
       " 'interpret',\n",
       " 'manipulate',\n",
       " 'human',\n",
       " 'language',\n",
       " 'nlp',\n",
       " 'has',\n",
       " 'many',\n",
       " 'real-world',\n",
       " 'applications',\n",
       " 'including',\n",
       " 'machine',\n",
       " 'translation',\n",
       " 'sentiment',\n",
       " 'analysis',\n",
       " 'chatbots']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-13T17:06:12.700994Z",
     "start_time": "2025-09-13T17:06:12.687180Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 5. Stemming:\n",
    "def stem(word):\n",
    "    for suffix in ['ing', 'ed', 'es', 's']:\n",
    "        if word.endswith(suffix) and len(word) > len(suffix) + 2:\n",
    "            return word[:-len(suffix)]\n",
    "    return word\n",
    "\n",
    "tokens_stemmed = [stem(word) for word in tokens_stop_words_removed]\n",
    "tokens_stemmed"
   ],
   "id": "9c3f16d141b6b222",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['natural',\n",
       " 'language',\n",
       " 'process',\n",
       " 'nlp',\n",
       " 'subfield',\n",
       " 'linguistic',\n",
       " 'computer',\n",
       " 'science',\n",
       " 'artificial',\n",
       " 'intelligence',\n",
       " 'concern',\n",
       " 'with',\n",
       " 'interaction',\n",
       " 'between',\n",
       " 'computer',\n",
       " 'human',\n",
       " 'language',\n",
       " \"it'\",\n",
       " 'used',\n",
       " 'analyze',\n",
       " 'text',\n",
       " 'allow',\n",
       " 'machin',\n",
       " 'understand',\n",
       " 'interpret',\n",
       " 'manipulate',\n",
       " 'human',\n",
       " 'language',\n",
       " 'nlp',\n",
       " 'has',\n",
       " 'many',\n",
       " 'real-world',\n",
       " 'application',\n",
       " 'includ',\n",
       " 'machine',\n",
       " 'translation',\n",
       " 'sentiment',\n",
       " 'analysi',\n",
       " 'chatbot']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-13T17:06:12.763691Z",
     "start_time": "2025-09-13T17:06:12.748972Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Bonus: Lemmatization:\n",
    "\n",
    "lemmatization_dict = {\n",
    "    \"is\": \"be\",\n",
    "    \"are\": \"be\",\n",
    "    \"was\": \"be\",\n",
    "    \"were\": \"be\",\n",
    "    \"has\": \"have\",\n",
    "    \"had\": \"have\",\n",
    "    \"used\": \"use\",\n",
    "}\n",
    "def simple_lemmatize(word):\n",
    "    return lemmatization_dict.get(word, word)\n",
    "tokens_lemmatized = [simple_lemmatize(word) for word in tokens_stemmed]\n",
    "tokens_lemmatized"
   ],
   "id": "7a6c733cc8e60161",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['natural',\n",
       " 'language',\n",
       " 'process',\n",
       " 'nlp',\n",
       " 'subfield',\n",
       " 'linguistic',\n",
       " 'computer',\n",
       " 'science',\n",
       " 'artificial',\n",
       " 'intelligence',\n",
       " 'concern',\n",
       " 'with',\n",
       " 'interaction',\n",
       " 'between',\n",
       " 'computer',\n",
       " 'human',\n",
       " 'language',\n",
       " \"it'\",\n",
       " 'use',\n",
       " 'analyze',\n",
       " 'text',\n",
       " 'allow',\n",
       " 'machin',\n",
       " 'understand',\n",
       " 'interpret',\n",
       " 'manipulate',\n",
       " 'human',\n",
       " 'language',\n",
       " 'nlp',\n",
       " 'have',\n",
       " 'many',\n",
       " 'real-world',\n",
       " 'application',\n",
       " 'includ',\n",
       " 'machine',\n",
       " 'translation',\n",
       " 'sentiment',\n",
       " 'analysi',\n",
       " 'chatbot']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-13T17:06:12.794986Z",
     "start_time": "2025-09-13T17:06:12.779033Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "a1914f436257cab0",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
