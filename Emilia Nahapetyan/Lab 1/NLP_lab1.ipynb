{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "text = \"\"\"Natural Language Processing (NLP) is a subfield of linguistics, computer science, and artificial\n",
        "intelligence concerned with the interactions between computers and human language. It's used to\n",
        "analyze text, allowing machines to understand, interpret, and manipulate human language. NLP has\n",
        "many real-world applications, including machine translation, sentiment analysis, and chatbots.\"\"\"\n",
        "\n"
      ],
      "metadata": {
        "id": "7bDn9bTdRA9O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokens = text.split()\n",
        "print(tokens)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x1a_jyaTR_w2",
        "outputId": "80f8f756-9966-4879-cf45-293abfea8996"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Natural', 'Language', 'Processing', '(NLP)', 'is', 'a', 'subfield', 'of', 'linguistics,', 'computer', 'science,', 'and', 'artificial', 'intelligence', 'concerned', 'with', 'the', 'interactions', 'between', 'computers', 'and', 'human', 'language.', \"It's\", 'used', 'to', 'analyze', 'text,', 'allowing', 'machines', 'to', 'understand,', 'interpret,', 'and', 'manipulate', 'human', 'language.', 'NLP', 'has', 'many', 'real-world', 'applications,', 'including', 'machine', 'translation,', 'sentiment', 'analysis,', 'and', 'chatbots.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokens_lowercase = [token.lower() for token in tokens]\n",
        "\n",
        "print(tokens_lowercase)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NfM4g4_SSVdm",
        "outputId": "e74c5a07-57d1-4ef8-cafa-0bdfac161e60"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['natural', 'language', 'processing', '(nlp)', 'is', 'a', 'subfield', 'of', 'linguistics,', 'computer', 'science,', 'and', 'artificial', 'intelligence', 'concerned', 'with', 'the', 'interactions', 'between', 'computers', 'and', 'human', 'language.', \"it's\", 'used', 'to', 'analyze', 'text,', 'allowing', 'machines', 'to', 'understand,', 'interpret,', 'and', 'manipulate', 'human', 'language.', 'nlp', 'has', 'many', 'real-world', 'applications,', 'including', 'machine', 'translation,', 'sentiment', 'analysis,', 'and', 'chatbots.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "punctuation = ['.', ',', '(', ')', '-', \"'\", ]\n",
        "cleaned_tokens = []\n",
        "for token in tokens_lowercase:\n",
        "    cleaned_token = ''.join([i for i in token if i not in punctuation])\n",
        "    cleaned_tokens.append(cleaned_token)\n",
        "print(cleaned_tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KhaJqLT6SiP-",
        "outputId": "d1a9b66c-148c-4f38-c19c-eccd44666113"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['natural', 'language', 'processing', 'nlp', 'is', 'a', 'subfield', 'of', 'linguistics', 'computer', 'science', 'and', 'artificial', 'intelligence', 'concerned', 'with', 'the', 'interactions', 'between', 'computers', 'and', 'human', 'language', 'its', 'used', 'to', 'analyze', 'text', 'allowing', 'machines', 'to', 'understand', 'interpret', 'and', 'manipulate', 'human', 'language', 'nlp', 'has', 'many', 'realworld', 'applications', 'including', 'machine', 'translation', 'sentiment', 'analysis', 'and', 'chatbots']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stop_words = [\"the\", \"a\", \"an\", \"in\", \"on\", \"at\", \"for\", \"to\", \"of\", \"and\", \"is\", \"are\"]\n",
        "\n",
        "def remove_stopwords(tokens, stop_words):\n",
        "    return [token for token in tokens if token not in stop_words]\n",
        "\n",
        "tokens_no_stopwords = remove_stopwords(cleaned_tokens, stop_words)\n",
        "print(tokens_no_stopwords)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IBqAO1jESpxu",
        "outputId": "ee2cc2ed-1d82-4156-9f19-3c5140311868"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['natural', 'language', 'processing', 'nlp', 'subfield', 'linguistics', 'computer', 'science', 'artificial', 'intelligence', 'concerned', 'with', 'interactions', 'between', 'computers', 'human', 'language', 'its', 'used', 'analyze', 'text', 'allowing', 'machines', 'understand', 'interpret', 'manipulate', 'human', 'language', 'nlp', 'has', 'many', 'realworld', 'applications', 'including', 'machine', 'translation', 'sentiment', 'analysis', 'chatbots']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "suffixes = ['ing', 'ed', 'es', 's']\n",
        "stemmed_tokens = []\n",
        "for token in tokens_no_stopwords:\n",
        "    for suffix in suffixes:\n",
        "        if token.endswith(suffix):\n",
        "            token = token[:-len(suffix)]\n",
        "    stemmed_tokens.append(token)\n",
        "\n",
        "print(stemmed_tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hEWBtPmhS2AW",
        "outputId": "a82a95e6-cb1e-46fa-847c-10df87a13b51"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['natural', 'language', 'proces', 'nlp', 'subfield', 'linguistic', 'computer', 'science', 'artificial', 'intelligence', 'concern', 'with', 'interaction', 'between', 'computer', 'human', 'language', 'it', 'u', 'analyze', 'text', 'allow', 'machin', 'understand', 'interpret', 'manipulate', 'human', 'language', 'nlp', 'ha', 'many', 'realworld', 'application', 'includ', 'machine', 'translation', 'sentiment', 'analysi', 'chatbot']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lemmatization_dict = {\n",
        "    \"is\": \"be\",\n",
        "    \"are\": \"be\",\n",
        "    \"has\": \"have\"\n",
        "}\n",
        "\n",
        "lemmatized_tokens = [lemmatization_dict.get(word, word) for word in tokens_lowercase]\n",
        "print(lemmatized_tokens)"
      ],
      "metadata": {
        "id": "NWThCfI1S_WG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f18e3a00-0d64-4f3a-9cae-37414a0938e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['natural', 'language', 'processing', '(nlp)', 'be', 'a', 'subfield', 'of', 'linguistics,', 'computer', 'science,', 'and', 'artificial', 'intelligence', 'concerned', 'with', 'the', 'interactions', 'between', 'computers', 'and', 'human', 'language.', \"it's\", 'used', 'to', 'analyze', 'text,', 'allowing', 'machines', 'to', 'understand,', 'interpret,', 'and', 'manipulate', 'human', 'language.', 'nlp', 'have', 'many', 'real-world', 'applications,', 'including', 'machine', 'translation,', 'sentiment', 'analysis,', 'and', 'chatbots.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BvgQd_o6TCGm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}